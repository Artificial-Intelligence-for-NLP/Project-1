{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lession 5 Programming & Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 文本检测的时候， 如何在已知一个文本的时候， **快速**的获得与其最为接近（相似的文本）; \n",
    "    + KNN\n",
    "    + 输入一篇文本 ==> tfidf / 某种向量距离上与其距离最接近的\n",
    "    + ==》 一些单词 ==》 输出一些和他距离最相近的文本\n",
    "    + <==================> 小米， 手机 \n",
    "    + **搜索引擎**\n",
    "2. 做爬虫的时候， 如何解决IP被封的问题； \n",
    "    + Random\n",
    "    + 豆瓣这个问题， 是不需要代理IP池\n",
    "3. 判定是不是新华社的； tfidf, sklearn\n",
    "4. tfidf 是总的一起算吗？ \n",
    "    tfidf 训练集 测试集 一起算； \n",
    "    tfidf vectorized \n",
    "    ```\n",
    "    {\n",
    "        ‘个性’: 1, \n",
    "        '文本'：2, \n",
    "    }\n",
    "    ```\n",
    "    vectorized.vectorize(['', '', ''])\n",
    "    vectorized\n",
    "5. 抄袭; 训练器; \n",
    "6. 爬虫: @曾锐鸿；电影部数；3万条电影评论记录 @曾锐鸿\n",
    "    + requests 很慢\n",
    "    + 豆瓣评分； \n",
    "    + 解析； \n",
    "    + BFS: 爬虫， 搜索引擎\n",
    "    **BSF** --> 肖申克的救赎 --> \n",
    "7. 如何减小向量长度 @Rambo\n",
    "8. 跑不起来，新的数据集合训练集合的向量不一样 @孙琴\n",
    "9. accuracy, editdistance 文本相似度的比较 @王子丰\n",
    "10. 效果的问题  @张楠\n",
    "    \n",
    "### Theory \n",
    "\n",
    "1. Bayes Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. BSF\n",
    "2. pandas 一些使用方式\n",
    "3. 机器学习模型最基本的一个过程\n",
    "4. 大量数据检索， 已知一个文本， 获得与其最相近的文本； Inforamtion Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text1  = '8. 跑不起来，新的数据集合训练集合的向量不一样 @孙， 感觉用Editdistance判别相似度效果不好，我用的是余弦距离.'\n",
    "text2  = '8. 跑不起来，新的数据集合训练集合的向量不一样 @孙， 感觉用Editdistance判别相似度效果不好，我们用的是余弦距离.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1. 疑似抄袭的文本其实不太多； \n",
    "2. 300 - 400； ===》 100； 3， 4 ==》 16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "already_visited = set()\n",
    "\n",
    "while ####: \n",
    "    if link in already_visited: continue\n",
    "    already_visited.add(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 1. max_feature ; 1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from jieba.posseg import cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "string = '我今天早上吃了两碗面， 然后去了景山公园'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_n(tag): return tag.startswith('n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS OF TAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/4l/c_tcf0j90c1d07h0xr4c4ql40000gn/T/jieba.cache\n",
      "Loading model cost 1.560 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我/r\n",
      "今天/t\n",
      "早上/t\n",
      "吃/v\n",
      "了/ul\n",
      "两碗/m\n",
      "面/n\n",
      "，/x\n",
      " /x\n",
      "然后/c\n",
      "去/v\n",
      "了/ul\n",
      "景山公园/ns\n"
     ]
    }
   ],
   "source": [
    "for w in cut(string): \n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 常见的词组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new york city\n",
    "小黄车 \n",
    "共享单车"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phrase Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cooccurance \n",
    "# word vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Sikp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorized = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = ['I am a boy', 'You are a girl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'am': 0, 'are': 1, 'boy': 2, 'girl': 3, 'you': 4}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized.transform(['She is a gril'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'am': 0, 'are': 1, 'boy': 2, 'girl': 3, 'you': 4}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized.transform(['She is a gril'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'am': 0, 'are': 1, 'boy': 2, 'girl': 3, 'you': 4}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## tfidf ## ==> word embedding ==> senetence embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = ['link_' + str(i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['link_0',\n",
       " 'link_1',\n",
       " 'link_2',\n",
       " 'link_3',\n",
       " 'link_4',\n",
       " 'link_5',\n",
       " 'link_6',\n",
       " 'link_7',\n",
       " 'link_8',\n",
       " 'link_9']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = {\n",
    "    'link_0': {'link_1', 'link_5', 'link_6'}, \n",
    "    'link_1': {'link_0', 'link_5', 'link_2', 'link_4'}, \n",
    "    'link_2': {'link_1', 'link_3', 'link_6'}, \n",
    "    'link_3': {'link_2', 'link_4', 'link_5'},\n",
    "    'link_4': {'link_3', 'link_1', 'link_5'},\n",
    "    'link_5': {'link_4', 'link_6', 'link_0', 'link_1'},\n",
    "    'link_6': {'link_0', 'link_5'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unvisited = []\n",
    "unvisited.append('link_0')\n",
    "visited = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'link_1', 'link_5', 'link_6'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G['link_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node: link_0 span: {'link_6', 'link_5', 'link_1'}\n",
      "node: link_6 span: {'link_0', 'link_5'}\n",
      "node: link_5 span: {'link_6', 'link_4', 'link_0', 'link_1'}\n",
      "node: link_1 span: {'link_2', 'link_4', 'link_0', 'link_5'}\n",
      "need_visited link_0 has been visited\n",
      "need_visited link_5 has been visited\n",
      "need_visited link_6 has been visited\n",
      "node: link_4 span: {'link_5', 'link_3', 'link_1'}\n",
      "need_visited link_0 has been visited\n",
      "need_visited link_1 has been visited\n",
      "node: link_2 span: {'link_6', 'link_3', 'link_1'}\n",
      "need_visited link_4 has been visited\n",
      "need_visited link_0 has been visited\n",
      "need_visited link_5 has been visited\n",
      "need_visited link_5 has been visited\n",
      "node: link_3 span: {'link_2', 'link_4', 'link_5'}\n",
      "need_visited link_1 has been visited\n",
      "need_visited link_6 has been visited\n",
      "need_visited link_3 has been visited\n",
      "need_visited link_1 has been visited\n",
      "need_visited link_2 has been visited\n",
      "need_visited link_4 has been visited\n",
      "need_visited link_5 has been visited\n"
     ]
    }
   ],
   "source": [
    "while len(unvisited) > 0: \n",
    "    need_visited = unvisited.pop(0)\n",
    "    if need_visited in visited:\n",
    "        print('need_visited {} has been visited'.format(need_visited))\n",
    "\n",
    "        continue\n",
    "    new_added_visited = G[need_visited]\n",
    "    print('node: {} span: {}'.format(need_visited, new_added_visited))\n",
    "    visited.add(need_visited) ## add to visited\n",
    "    unvisited += list(new_added_visited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv('../dataset/export_sql_1558435.zip', compression='zip', encoding='gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = news.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "news['is_xinhua'] = np.where(news['source'].str.contains('新华'), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## posseg n, filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cut(string): return ' '.join(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = news.sample(n=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "news['content'] = news['content'].apply(cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news['title'] = news['title'].apply(cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_c = news['content'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_t = news['title'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorized = TfidfVectorizer(max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_c_v = vectorized.fit_transform(X_c)\n",
    "X_t_v = vectorized.fit_transform(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = news['is_xinhua'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4392"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 for i in y if i != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8784"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4392 / 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GaussianNB(priors=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### title, content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 10000)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_c_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 10000)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t_v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, test, validation data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train: \n",
    "## test: \n",
    "## validation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(X_t_v, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_t_v_ndarray = X_t_v.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2627316250087499,\n",
       " 0.39216965880597415,\n",
       " 0.1378863136854586,\n",
       " 0.4376101566233954,\n",
       " 0.39216965880597415,\n",
       " 0.4376101566233954,\n",
       " 0.1727930195426041,\n",
       " 0.4376101566233954]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: x != 0, X_t_v_ndarray[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_c_x, test_c_x, trian_c_y, test_c_y = train_test_split(X_c_v, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_split = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_split = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = np.arange(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_indices = indices[int(len(indices) * valid_split):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_train_indices = indices[:int(len(indices) * valid_split)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_indices = test_train_indices[: int(len(test_train_indices) * test_split)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_indices = test_train_indices[int(len(test_train_indices) * test_split): ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3612"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "638"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_c_train, X_c_test, X_c_val = X_c_v[train_indices], X_c_v[test_indices], X_c_v[validation_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_t_train, X_t_test, X_t_val = X_t_v[train_indices], X_t_v[test_indices], X_t_v[validation_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train, y_test, y_val = y[train_indices], y[test_indices], y[validation_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=[0.5, 0.5])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_t_train.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_performance(clf, X_, y_, sample=1000):\n",
    "    random_indices = np.random.choice(np.arange(len(y_)), sample)\n",
    "    sub_x = X_[random_indices]\n",
    "    sub_y = y_[random_indices]\n",
    "    y_hat = clf.predict(sub_x.toarray())\n",
    "    print('percision is: {}'.format(precision_score(sub_y, y_hat)))\n",
    "    print('recall is: {}'.format(recall_score(sub_y, y_hat)))\n",
    "    print('roc_auc is: {}'.format(roc_auc_score(sub_y, y_hat)))\n",
    "    print('confusion matrix: \\n{}'.format(confusion_matrix(sub_y, y_hat, labels=[0, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percision is: 1.0\n",
      "recall is: 0.9977220956719818\n",
      "roc_auc is: 0.998861047835991\n",
      "confusion matrix: \n",
      "[[122   0]\n",
      " [  2 876]]\n"
     ]
    }
   ],
   "source": [
    "get_performance(clf, X_t_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percision is: 0.9315375982042648\n",
      "recall is: 0.9496567505720824\n",
      "roc_auc is: 0.7327648832225491\n",
      "confusion matrix: \n",
      "[[ 65  61]\n",
      " [ 44 830]]\n"
     ]
    }
   ],
   "source": [
    "get_performance(clf, X_t_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat_test =  clf.predict(X_t_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "candidate_indices = []\n",
    "for index, (y, yhat)  in enumerate(zip(y_test, y_hat_test)):\n",
    "    if y == 0 and yhat == 1: \n",
    "        candidate_indices.append(test_indices[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'（ 原 标题 ： 叙利亚 “ 喋血 男孩 ” 之 父 ： 有人 利用 我 儿子 说谎 ） \\r\\n 你 还 记着 去年 8 月 震惊 全球 的 那段 “ 阿勒颇 喋血 男孩 ” 的 视频 吗 ？ 5 岁 的 奥姆 兰 （ Omran   Daqneesh ） 被 人 从 瓦砾 中抱 出来 ， 送 进 救护车 里 。 在 救护车 里 满身 灰土 和 血迹 的 他 ， 似乎 被 发生 的 一切 惊吓 到 ， 甚至 忘记 了 哭泣 。 这 一幕 被 诸多 西方 媒体 用来 暗示 叙利亚 政府 是 “ 人民 屠夫 ” 。 \\r\\n （ 2016 年 8 月 奥姆 兰 的 故事 曾经 被 西方 媒体 “ 刷屏 ” ， 多家 媒体 以此 反复 暗示 作 叙利亚 政府 “ 屠杀 平民 ” ） \\r\\n 时隔 8 个 月 ， 奥姆 兰 的 父亲 终于 决定 站 了 出来 。 央视 记者 6 月 19 日 对 奥姆 兰及 奥姆 兰 父亲 的 专访 中 ， 奥姆 兰 父亲 穆罕默德 （ Mohamed   Kheir   Daqneesh ） 直接 指责 ， 反 政府 武装 和 所谓 的 “ 白 头盔 ” 组织 在 利用 他 的 儿子 ， 达到 反对 政府 的 目的 。 \\r\\n 奥姆 兰 父亲 还原 真相 \\r\\n — — 奥姆 兰 父亲 不 确认 是 叙 政府军 空袭 \\r\\n — — “ 白 头盔 ” 从 他 手中 夺走 奥姆 兰送 进 救护车 \\r\\n — — 奥姆 兰 头部 受伤 不 大   血 来自 父亲 \\r\\n （ 照片 摄影 ： 徐德智 ） \\r\\n 奥姆 兰 父亲 默罕 默德 在 自己 位于 阿勒颇 东部 的 家里 接待 了 我们 一行 。 他 说 ， 这里 并 不是 事件 发生 地点 。 在 2016 年 由于 这片 区域 成为 了 前线 ， 他 不得不 另外 租 了 一处 比较 安全 的 公寓 。 \\r\\n 穆罕默德 说 ， 去年 8 月 的 一天 ， 他 和 奥姆 兰及 奥姆 兰 的 哥哥 姐姐 们 在 家里 ， 当时 他们 在 浏览 手机 照片 。 突然 家里 的 灯 全部 灭 了 ， 听到 旁边 爆发 出 巨大 的 声响 ， 随后 自己 的 楼房 也 开始 晃动 ， 掉落 了 一些 碎石 。 在 沙发 上 的 奥姆 兰 左侧 眉头 附近 被 一块 小石头 击中 ， 自己 的 手 也 受伤 了 。 默罕 默德 抱 着 奥姆 兰从 房间 里 出去 ， 不 注意 把 血迹 抹 到 了 奥姆 兰 的 身上 。 \\r\\n “ 奥姆 兰 受伤 的 情况 并不大 ， 他们 对 这点 进行 了 夸大 。 ” 默罕 默德 说 。 \\r\\n 他 告诉 我们 ， 当 他 把 奥姆 兰抱 出 房间 后 ， “ 白 头盔 ” 的 人 一把 抢过 了 奥姆 兰 ， 放上 了 救护车 — — 儿子 莫名其妙 从 父亲 处 被 夺走 ， 这才 有 了 本来 已经 受到 惊吓 的 奥姆 兰 ， 在 后座 上 如此 不知所措 的 表情 。 \\r\\n 我们 一直 在 问 一个 关键问题 ： 这次 袭击 是 政府军 的 空袭 吗 ？ 默罕 默德 无奈 地 摇摇头 ： “ 我们 在 房间 里 ， 当时 也 没有 听到 战斗机 的 声音 ， 不过 我们 也 不 知道 到底 谁 打 了 这 一炮 。 ” 2016 年 8 月 的 阿勒颇 ， 处在 两次 “ 停火 ” 之间 ， 可以 说 情况 复杂 ， 谁 也 有 可能 是 袭击 的 罪魁祸首 。 \\r\\n （ 照片 摄影 ： 徐德智 ） \\r\\n “ 战争 明星 ” 的 苦恼 \\r\\n — — 奥姆 兰 父亲 觉得 儿子 被 利用 \\r\\n — — 有 媒体 提供 10000 美元 让 他 指责 政府 \\r\\n — — 拒绝 了 出国 生活 的 机会 \\r\\n — — 受到 威胁   不得不 躲 在 家里 \\r\\n 随后 ， 奥姆 兰 的 视频 传遍 了 互联网 ， 美国有线电视新闻网 女主播 更是 哭 得 不成人 样 。 奥姆 兰 成为 了 反 政府 武装 塑造 的 政府 残害 平民 的 形象 。 大约 三天 后 ， 默罕 默德 知道 了 自己 儿子 在 网上 成为 “ 名人 ” 的 消息 — — 但是 这 却 让 他 感到 ， 自己 的 儿子 被 利用 了 。 \\r\\n “ 我 不在乎 这种 名气 ， （ 反 政府 武装 ） 通过 我 的 儿子 在 试图 肢解 这个 国家 ！ 别忘了 ， 是 他们 先 打进 了 阿勒颇 ， 然后 让 人们 受到 这样 的 伤害 的 。 ” \\r\\n 默罕 默德 给 我们 看 了 一段 来自 海湾 国家 媒体 的 视频 ， 在 视频 中 主持人 公开 地 宣称 ， “ 给 奥姆 兰 父亲 10000 美元 来 接受 采访 ， 谈谈 这个 政府 干 的 坏事 。 ” 而 包括 美国 在内 的 多个 国家 的 政府 或者 组织 机构 ， 都 向 默罕 默德 一家 伸出 橄榄枝 ， 要 请 他们 前往 生活 ， 甚至 提供 住所 、 工作 、 保险 ， 面对 突如其来 的 网络 名人效应 ， 奥姆 兰 父亲 拒绝 了 所有 的 要求 。 \\r\\n 由于 奥姆 兰 父亲 的 “ 不 配合 ” 姿态 ， 在 去年 反 政府 武装 控制 期间 ， 他 遭到 了 数次 威胁 。 “ 他们 宣布 奥姆 兰 和 他 姐姐 的 死讯 ， 一共 宣布 了 五次 。 ” 穆罕默德 无奈 地 告诉 我们 。 \\r\\n 本来 阿勒颇 东部 就 不 稳定 ， 再 加上 武装人员 的 不停 威胁 ， 他们 全家 几乎 深居 在 房间 里 ， 很少 出门 。 为了 不让 人 认出 奥姆 兰 ， 默罕 默德 甚至 完全 给 儿子 换 了 一个 新 的 发型 ， 好 让 大家 都 看不出 ， 这 就是 那个 “ 战争 男孩 ” 。 \\r\\n ? （ 照片 摄影 ： 徐德智 ） \\r\\n ? 时隔 8 个 月 终于 发声 \\r\\n — — 局势 转好   是 时候 真相大白 了 \\r\\n — — 现在 的 生活状况 更好 \\r\\n — — “ 战争 之子 ” 期待 变 “ 和 平之子 ” \\r\\n 其实 在 接受 我们 采访 前 ， 奥姆 兰 的 父亲 已经 在 叙利亚 国家 电视台 将 他 的 故事 告诉 了 叙利亚人 。 随后 包括 《 纽约时报 》 在内 的 西方 媒体 说 ， 默罕 默德 是 在 利用 奥姆 兰 ， 实现 自己 的 政治 诉求 ， 把 整个 事件 政治化 。 对 这种 说法 ， 奥姆 兰 父亲 无法 认同 。 \\r\\n “ 我们 沉默 着 ， 他们 （ 反 政府 武装 ） 一直 宣传 着 。 而且 不 经过 我 同意 ， 捏造 我 和 奥姆 兰 的 故事 ， 这 是 不 对 的 。 ” \\r\\n 采访 的 时候 ， 全家人 显得 神情 轻松 甚至 面 带 笑意 ， 奥姆 兰 的 父亲 说 ， 上午 全家 去逛 了 公园 ， 心情 特别 好 。 默罕 默德 一直 在 做 金属 原料 的 加工 ， 他 说 虽然 生意 总有 波动 ， 但是 现在 的 状况 实在 是 比 去年 在 反 政府 武装 控制 的 地区 好太多 。 \\r\\n “ 叙利亚 曾经 是 世界 上 最 安全 的 地方 之一 ， 我们 随时 都 能 去 任何 地方 。 危机 爆发 后 ， 一切 都 变 了 ， 打砸抢 烧 到处 发生 。 我 的 作坊 也 被 抢 过 。 现在 感觉 阿勒颇 正在 恢复 原来 的 生机 。 ” \\r\\n 奥姆 兰 还有 一年 就要 走进 校园 开始 读书 了 ， 默罕 默德 希望 未来 奥姆 兰能 为 大家 所 记住 ， 不是 因为 他 代表 了 战争 的 残酷 和 政府 的 血腥 。 他 说 ， 他 希望 儿子 不是 “ 战争 之子 ” ， 而 成为 整个 叙利亚 的 “ 和 平之子 ” 。 \\r\\n'"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.iloc[2175]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'本报讯 （ 记者   卢文军   通讯员   张效强   周 艳丽   文 / 图 ） 中牟县 第十三届 西瓜 擂台赛 日前 举行 ， 57 斤 的 大 西瓜 夺得 本届 的 “ 瓜王 ” 称号 。 \\r\\n 本届 擂台赛 内容 和 形式 更加 丰富 和 新颖 。 来自 姚家 、 韩寺 、 官渡 、 东风路 办事处 等 乡 （ 镇 、 街道 ） 的 260 多名 种瓜 高手 参加 比赛 。 最终 ， 来自 韩寺 镇 小孟庄 的 孟振方 以 综合 评分 92.97 、 糖度 12 的 成绩 获得 本届 西瓜 擂台赛 的 擂主 ； 姚家 镇大洪村 的 校进 栓以 57 斤 的 大 西瓜 夺得 本届 的 “ 瓜王 ” 称号 。 \\r\\n'"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.iloc[2480]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'在 安装 了 iOS   11 之后 ， 在 设置 过程 中 ， 会 出现 一个 新 的 选项 ， 可以 从 现有 设备 （ 也 需要 运行 iOS   11 ） 传输 设置 信息 。 新 设备 需要 放在 旧 设备 的 旁边 ， 两部 设备 靠近 时 将 获得 配对 的 说明 。 \\r\\n 配对 时 需要 使用 旧 设备 的 摄像头 来 扫描 新 设备 上 的 类似 Apple   Watch 配对 风格 的 图像 。 之后 ， 系统 将 提示 您 输入 旧 设备 的 密码 ， 这 也 将 成为 新 设备 上 的 密码 ， 然后 设备 在 传输 过程 中 需要 保持 靠近 。   传输 配置 信息 只 需 几分钟 即可 完成 。 \\r\\n 在 两个 设备 配对 后 还有 一个 新 的 简化 设置 过程 ， 用于 激活 Touch   ID ， 然后 启用 设置 ， 如 查找 我 的 iPhone ， 位置 等 。 之后 ， 用户 可以 设置 Apple   Pay 和 Siri ， 然后 开始 使用 新 设备 。   iOS   11 目前 仅限于 开发人员 ， 但 本月 晚些时候 将 提供 给 公开 测试人员 。 \\r\\n 访问 : \\r\\n 苹果 在线 商店 ( 中国 ) \\r\\n'"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.iloc[3542]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2175,\n",
       " 2480,\n",
       " 3542,\n",
       " 4346,\n",
       " 511,\n",
       " 1187,\n",
       " 761,\n",
       " 2942,\n",
       " 3588,\n",
       " 4544,\n",
       " 2958,\n",
       " 3842,\n",
       " 2097,\n",
       " 583,\n",
       " 3928,\n",
       " 2177,\n",
       " 1067,\n",
       " 2740,\n",
       " 3799,\n",
       " 2014,\n",
       " 270,\n",
       " 2571,\n",
       " 918,\n",
       " 2793,\n",
       " 4910,\n",
       " 3800,\n",
       " 2159,\n",
       " 3151,\n",
       " 3512,\n",
       " 2441,\n",
       " 604,\n",
       " 3328,\n",
       " 4306,\n",
       " 3926,\n",
       " 2725,\n",
       " 3324,\n",
       " 2991,\n",
       " 4404,\n",
       " 3486]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Retrieve || KNN || Cosine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
